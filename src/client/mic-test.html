<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Microphone Test - Server Transcription</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 900px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .test-container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
        }
        .mode-selector {
            margin: 20px 0;
            padding: 15px;
            background: #e3f2fd;
            border-radius: 5px;
        }
        .mode-selector button {
            margin: 0 10px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 14px;
        }
        .mode-selector button.active {
            background: #1976d2;
            color: white;
        }
        .mic-button {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 40px;
            cursor: pointer;
            margin: 20px 0;
            transition: all 0.3s;
        }
        .mic-button:hover {
            transform: scale(1.1);
        }
        .mic-button.recording {
            background: #ff4444;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        .status {
            margin: 20px 0;
            padding: 15px;
            border-radius: 5px;
            font-size: 16px;
        }
        .status.info { background: #e3f2fd; color: #1976d2; }
        .status.success { background: #e8f5e9; color: #388e3c; }
        .status.error { background: #ffebee; color: #d32f2f; }
        .log {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            max-height: 400px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
            margin-top: 20px;
        }
        .log-entry {
            margin: 5px 0;
            padding: 5px;
            border-left: 3px solid #666;
            padding-left: 10px;
        }
        .transcript {
            background: #fff3e0;
            padding: 15px;
            border-radius: 5px;
            margin-top: 20px;
            font-size: 18px;
            min-height: 50px;
        }
        .api-response {
            background: #f3e5f5;
            padding: 15px;
            border-radius: 5px;
            margin-top: 20px;
            font-family: monospace;
            font-size: 12px;
            white-space: pre-wrap;
            max-height: 300px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div class="test-container">
        <h1>🎤 Microphone Test - Server Transcription</h1>
        <p>Test server-side audio transcription with detailed API debugging.</p>

        <div class="mode-selector">
            <strong>Mode:</strong>
            <button id="webSpeechBtn" class="active">Web Speech API</button>
            <button id="serverBtn">Server Transcription</button>
        </div>

        <button id="micBtn" class="mic-button">🎤</button>

        <div id="status" class="status info">
            Click the microphone to start
        </div>

        <div class="transcript">
            <strong>Transcript:</strong>
            <div id="transcript">Nothing recorded yet...</div>
        </div>

        <div class="api-response">
            <strong>API Response:</strong>
            <div id="apiResponse">No API calls yet...</div>
        </div>

        <div class="log">
            <strong>Debug Log:</strong>
            <div id="log"></div>
        </div>
    </div>

    <script>
        let recognition = null;
        let mediaRecorder = null;
        let isRecording = false;
        let mode = 'webspeech'; // 'webspeech' or 'server'

        const API_BASE = window.location.hostname === 'localhost'
            ? 'http://localhost:3500/api'
            : '/api';

        function addLog(message, type = 'info') {
            const logDiv = document.getElementById('log');
            const entry = document.createElement('div');
            entry.className = 'log-entry';
            entry.style.borderLeftColor = type === 'error' ? '#d32f2f' : type === 'success' ? '#388e3c' : '#666';
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
            logDiv.appendChild(entry);
            logDiv.scrollTop = logDiv.scrollHeight;
        }

        function updateStatus(message, type = 'info') {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
        }

        function showAPIResponse(data) {
            document.getElementById('apiResponse').textContent = JSON.stringify(data, null, 2);
        }

        // Web Speech API Mode
        function initWebSpeech() {
            addLog('Initializing Web Speech API...');
            addLog(`webkitSpeechRecognition: ${'webkitSpeechRecognition' in window}`);
            addLog(`SpeechRecognition: ${'SpeechRecognition' in window}`);

            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                try {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    recognition = new SpeechRecognition();
                    recognition.continuous = false;
                    recognition.interimResults = false;
                    recognition.lang = 'en-US';

                    recognition.onstart = () => {
                        addLog('Speech recognition started', 'success');
                        updateStatus('🎤 Listening... Speak now!', 'success');
                        isRecording = true;
                        document.getElementById('micBtn').classList.add('recording');
                    };

                    recognition.onresult = (event) => {
                        addLog(`Got result: ${event.results.length} results`, 'success');
                        const transcript = event.results[0][0].transcript;
                        addLog(`Transcript: "${transcript}"`, 'success');
                        document.getElementById('transcript').textContent = transcript;
                        updateStatus('✅ Speech recognized successfully!', 'success');
                    };

                    recognition.onend = () => {
                        addLog('Speech recognition ended');
                        updateStatus('Click the microphone to start', 'info');
                        isRecording = false;
                        document.getElementById('micBtn').classList.remove('recording');
                    };

                    recognition.onerror = (event) => {
                        addLog(`ERROR: ${event.error}`, 'error');
                        updateStatus(`❌ Error: ${event.error}`, 'error');
                        isRecording = false;
                        document.getElementById('micBtn').classList.remove('recording');
                    };

                    addLog('Web Speech API initialized successfully', 'success');
                    updateStatus('✅ Ready! Click microphone to test', 'success');
                } catch (error) {
                    addLog(`EXCEPTION: ${error.message}`, 'error');
                    updateStatus(`❌ Failed to initialize: ${error.message}`, 'error');
                    recognition = null;
                }
            } else {
                addLog('Web Speech API NOT supported', 'error');
                updateStatus('❌ Web Speech API not supported in this browser', 'error');
                recognition = null;
            }
        }

        // Server Transcription Mode
        async function startServerRecording() {
            try {
                addLog('Requesting microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                addLog('Microphone access granted', 'success');

                mediaRecorder = new MediaRecorder(stream);
                const audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        addLog(`Audio chunk: ${event.data.size} bytes`);
                    }
                };

                mediaRecorder.onstop = async () => {
                    addLog('Recording stopped');
                    isRecording = false;
                    document.getElementById('micBtn').classList.remove('recording');

                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    addLog(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`, 'success');

                    updateStatus('📤 Sending to server for transcription...', 'info');

                    try {
                        const formData = new FormData();
                        formData.append('audio', audioBlob, 'recording.webm');

                        addLog(`Sending POST to ${API_BASE}/transcribe`);
                        const response = await fetch(`${API_BASE}/transcribe`, {
                            method: 'POST',
                            body: formData
                        });

                        addLog(`Response status: ${response.status} ${response.statusText}`);

                        const result = await response.json();
                        addLog(`Response received`, 'success');
                        showAPIResponse(result);

                        if (result.success && result.text) {
                            addLog(`Transcription: "${result.text}"`, 'success');
                            document.getElementById('transcript').textContent = result.text;
                            updateStatus('✅ Transcription successful!', 'success');
                        } else {
                            addLog(`Transcription failed: ${result.error || result.message}`, 'error');
                            updateStatus(`❌ ${result.error || result.message}`, 'error');
                        }
                    } catch (error) {
                        addLog(`Network error: ${error.message}`, 'error');
                        updateStatus(`❌ Network error: ${error.message}`, 'error');
                        showAPIResponse({ error: error.message, stack: error.stack });
                    }

                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                document.getElementById('micBtn').classList.add('recording');
                addLog('Recording started', 'success');
                updateStatus('🎤 Recording... Speak now!', 'success');

                // Auto-stop after 5 seconds
                setTimeout(() => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        addLog('Auto-stopping after 5 seconds');
                        mediaRecorder.stop();
                    }
                }, 5000);

            } catch (error) {
                addLog(`Microphone error: ${error.message}`, 'error');
                updateStatus(`❌ Microphone error: ${error.message}`, 'error');
                isRecording = false;
            }
        }

        // Button handlers
        document.getElementById('webSpeechBtn').addEventListener('click', () => {
            mode = 'webspeech';
            document.getElementById('webSpeechBtn').classList.add('active');
            document.getElementById('serverBtn').classList.remove('active');
            addLog('Switched to Web Speech API mode');
            initWebSpeech();
        });

        document.getElementById('serverBtn').addEventListener('click', () => {
            mode = 'server';
            document.getElementById('serverBtn').classList.add('active');
            document.getElementById('webSpeechBtn').classList.remove('active');
            addLog('Switched to Server Transcription mode');
            updateStatus('✅ Ready! Click microphone to test', 'success');
        });

        document.getElementById('micBtn').addEventListener('click', () => {
            addLog(`Microphone button clicked (mode: ${mode})`);

            if (mode === 'webspeech') {
                if (!recognition) {
                    addLog('Recognition not available', 'error');
                    updateStatus('❌ Voice recognition not available', 'error');
                    return;
                }

                if (isRecording) {
                    addLog('Stopping Web Speech API');
                    recognition.stop();
                } else {
                    addLog('Starting Web Speech API');
                    try {
                        recognition.start();
                    } catch (error) {
                        addLog(`EXCEPTION: ${error.message}`, 'error');
                        updateStatus(`❌ Error: ${error.message}`, 'error');
                    }
                }
            } else if (mode === 'server') {
                if (isRecording) {
                    addLog('Already recording, please wait...');
                } else {
                    startServerRecording();
                }
            }
        });

        // Initialize on load
        window.addEventListener('DOMContentLoaded', () => {
            addLog('Page loaded');
            initWebSpeech();
        });
    </script>
</body>
</html>
