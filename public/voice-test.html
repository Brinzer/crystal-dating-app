<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Crystal Voice Test - Speech-to-Text</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 100%;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 32px;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 16px;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 50px;
            cursor: pointer;
            margin: 30px auto;
            display: block;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
        }

        .mic-button:hover {
            transform: scale(1.1);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
        }

        .mic-button:active {
            transform: scale(0.95);
        }

        .mic-button.recording {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
        }

        .status {
            text-align: center;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            font-size: 16px;
            font-weight: 500;
        }

        .status.idle {
            background: #e3f2fd;
            color: #1976d2;
        }

        .status.recording {
            background: #fff3e0;
            color: #f57c00;
        }

        .status.processing {
            background: #f3e5f5;
            color: #7b1fa2;
        }

        .status.success {
            background: #e8f5e9;
            color: #388e3c;
        }

        .status.error {
            background: #ffebee;
            color: #d32f2f;
        }

        .transcript-box {
            background: #f5f5f5;
            border-radius: 10px;
            padding: 20px;
            min-height: 150px;
            margin: 20px 0;
            font-size: 18px;
            line-height: 1.6;
            color: #333;
        }

        .transcript-box.empty {
            color: #999;
            font-style: italic;
        }

        .config {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
            margin-top: 20px;
        }

        .config h3 {
            margin-bottom: 15px;
            color: #333;
            font-size: 18px;
        }

        .config-item {
            margin: 10px 0;
        }

        .config-item label {
            display: block;
            margin-bottom: 5px;
            color: #666;
            font-size: 14px;
        }

        .config-item input,
        .config-item select {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
        }

        .config-item input:focus,
        .config-item select:focus {
            outline: none;
            border-color: #667eea;
        }

        .server-indicator {
            text-align: center;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 20px;
            font-size: 14px;
        }

        .server-indicator.online {
            background: #e8f5e9;
            color: #388e3c;
        }

        .server-indicator.offline {
            background: #ffebee;
            color: #d32f2f;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Crystal Voice Test</h1>
        <p class="subtitle">Speech-to-Text Demo</p>

        <div id="serverStatus" class="server-indicator offline">
            Server: Checking...
        </div>

        <button id="micBtn" class="mic-button" disabled>üé§</button>

        <div id="status" class="status idle">
            Click microphone to start recording
        </div>

        <div class="transcript-box empty" id="transcript">
            Your transcription will appear here...
        </div>

        <div class="config">
            <h3>‚öôÔ∏è Configuration</h3>

            <div class="config-item">
                <label for="serverUrl">Server URL:</label>
                <input type="text" id="serverUrl" value="https://evil-things-warn.loca.lt" />
            </div>

            <div class="config-item">
                <label for="recordingTime">Recording Duration (seconds):</label>
                <input type="number" id="recordingTime" value="5" min="1" max="30" />
            </div>

            <div class="config-item">
                <label>Last Transcription Time:</label>
                <input type="text" id="transcriptionTime" value="‚Äî" readonly />
            </div>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let isRecording = false;

        // Use localtunnel URL for speech-to-text server
        let serverUrl = 'https://evil-things-warn.loca.lt';

        const micBtn = document.getElementById('micBtn');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const serverStatus = document.getElementById('serverStatus');
        const serverUrlInput = document.getElementById('serverUrl');
        const recordingTimeInput = document.getElementById('recordingTime');
        const transcriptionTimeDiv = document.getElementById('transcriptionTime');

        // Update server URL from input
        serverUrlInput.addEventListener('change', () => {
            serverUrl = serverUrlInput.value;
            checkServerStatus();
        });

        // Check server status
        async function checkServerStatus() {
            try {
                const response = await fetch(`${serverUrl}/health`, {
                    method: 'GET',
                    signal: AbortSignal.timeout(3000)
                });

                if (response.ok) {
                    serverStatus.textContent = '‚úÖ Server: Online';
                    serverStatus.className = 'server-indicator online';
                    micBtn.disabled = false;
                } else {
                    throw new Error('Server not responding');
                }
            } catch (error) {
                serverStatus.textContent = '‚ùå Server: Offline';
                serverStatus.className = 'server-indicator offline';
                micBtn.disabled = true;
            }
        }

        // Update status display
        function updateStatus(message, type = 'idle') {
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
        }

        // Update transcript display
        function updateTranscript(text) {
            transcriptDiv.textContent = text;
            transcriptDiv.className = 'transcript-box';
        }

        // Start recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                const audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    isRecording = false;
                    micBtn.classList.remove('recording');

                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

                    updateStatus('üîÑ Converting to WAV...', 'processing');

                    try {
                        // Convert WebM to WAV
                        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const arrayBuffer = await audioBlob.arrayBuffer();
                        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

                        const wavBlob = audioBufferToWav(audioBuffer);

                        updateStatus('üì§ Transcribing...', 'processing');

                        const startTime = Date.now();

                        // Send to server
                        const formData = new FormData();
                        formData.append('file', wavBlob, 'recording.wav');
                        formData.append('model', 'whisper-1');

                        const response = await fetch(`${serverUrl}/v1/audio/transcriptions`, {
                            method: 'POST',
                            body: formData
                        });

                        const endTime = Date.now();
                        const duration = ((endTime - startTime) / 1000).toFixed(2);
                        transcriptionTimeDiv.value = `${duration}s`;

                        if (response.ok) {
                            const result = await response.json();
                            updateTranscript(result.text);
                            updateStatus(`‚úÖ Transcription complete! (${duration}s)`, 'success');
                        } else {
                            const error = await response.text();
                            updateStatus(`‚ùå Transcription failed: ${error}`, 'error');
                        }
                    } catch (error) {
                        updateStatus(`‚ùå Error: ${error.message}`, 'error');
                    }

                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                micBtn.classList.add('recording');
                updateStatus('üé§ Recording... Speak now!', 'recording');

                // Auto-stop after specified duration
                const recordingTime = parseInt(recordingTimeInput.value) * 1000;
                setTimeout(() => {
                    if (mediaRecorder && mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                    }
                }, recordingTime);

            } catch (error) {
                updateStatus(`‚ùå Microphone error: ${error.message}`, 'error');
                isRecording = false;
            }
        }

        // Convert AudioBuffer to WAV
        function audioBufferToWav(audioBuffer) {
            const numberOfChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const format = 1;
            const bitDepth = 16;

            const bytesPerSample = bitDepth / 8;
            const blockAlign = numberOfChannels * bytesPerSample;

            const data = [];
            for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                data.push(audioBuffer.getChannelData(i));
            }

            const interleaved = interleave(data);
            const dataLength = interleaved.length * bytesPerSample;
            const buffer = new ArrayBuffer(44 + dataLength);
            const view = new DataView(buffer);

            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + dataLength, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numberOfChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(view, 36, 'data');
            view.setUint32(40, dataLength, true);

            floatTo16BitPCM(view, 44, interleaved);

            return new Blob([buffer], { type: 'audio/wav' });
        }

        function interleave(channelData) {
            const length = channelData[0].length;
            const numberOfChannels = channelData.length;
            const result = new Float32Array(length * numberOfChannels);

            let offset = 0;
            for (let i = 0; i < length; i++) {
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    result[offset++] = channelData[channel][i];
                }
            }
            return result;
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        function floatTo16BitPCM(view, offset, input) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, input[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
        }

        // Microphone button click
        micBtn.addEventListener('click', () => {
            if (!isRecording) {
                startRecording();
            }
        });

        // Check server status on load
        checkServerStatus();

        // Recheck server status every 5 seconds
        setInterval(checkServerStatus, 5000);
    </script>
</body>
</html>
